---
title: 'Assignment #9'
author: "Anthony Conrardy"
date: "2024-03-23"
output:
  html_document:
    highlight: pygments
    theme: cerulean
    toc: true
    toc_float: true
  pdf_document:
    toc: true
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::include_graphics("C:/Users/para2/Documents/R_Working_Directory/pittsburgh+bridges/Assignment #9 DATA 607/Assignment Web APIs.png")
```

### API Key

I created an API key on the New York Times Website for access to their Best Seller Book List.  The API key is used within the request for information.  I loaded the following libraries:

httr2

jsonlite

tidyr

tidyverse

dplyr


```{r startup, include=FALSE}
library(httr2)
library(jsonlite)
library(tidyr)
library(tidyverse)
library(dplyr)
```

### Setting Up the Request

In this section we set up the interface in R to extract the information from the New York Times API.  We are going to structure the URL portion to make it easier to alter the request for information by having only 1/3 of the code need to be altered (end_url).  For this exercise, we are looking to extract information for best seller list containing the names of the hardcover graphic novels.

```{r API request}
# Sets the key for access to the New York Times API
api_key <- "fD4OklyPUpw9GHJo6q1cWcIblC9bbolV"

# Sets the base API portion of the url
base_url <- "https://api.nytimes.com/svc/books/v3"

# Sets the end point url.  This allows us to alter only this one portion of the URL to access 
#different requests.  For this assignment we were interested in identifying the hardcover 
#graphic novels on the best seller list.
end_url <- "/lists/hardcover-graphic-books.json"

# Pastes all three sections together so we can request the information.
url <- paste0(base_url,end_url,"?api-key=",api_key)
```

### Checking the Response

In this section we are going to check the connection to the API and then pull the data into a data frame so that we can examine and extract what we might need.

```{r response}
# Check the Response from the API
req_1 <- response_json(status_code = 200, url = url, method = "GET", headers = list(), body = list())
req_1 |> resp_raw()

# Pull the information request from the API
json_data <- fromJSON(url)
knitr::include_graphics("C:/Users/para2/Documents/R_Working_Directory/pittsburgh+bridges/Assignment #9 DATA 607/JSON_data_import.png")
```

### Extract the Relevent Information

In this section we are going to extract the data from a few levels down on the imported data and established frame, and then select the columns for our new data frame in the order that might be most beneficial. 

```{r extraction}
# Extract the Book Information on the Hardcover Graphic Novels
books <- json_data$results$books

# Select the Variables we are interested in.  The ISBN number are unique 
#identifiers, so I will pull them to the front and then add on what I may
#be interested in viewing or analyzing.

books_final <- books |> select(primary_isbn10, primary_isbn13, title, author, 
                       publisher, description,  amazon_product_url, weeks_on_list)

head(books_final, 3)

```

### Conclusion

This was most interesting exercise, as I had no idea something like this was possible from normally accessible laptop computers and platforms.  The availability of data through this avenue opens up further analysis and reporting by almost everyone with a computer, time and knowledge.

